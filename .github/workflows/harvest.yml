name: Harvest ESG leads

permissions:
  contents: write

on:
  schedule:
    # Runs daily at 01:00 UTC (~06:30 IST)
    - cron: "0 1 * * *"
  workflow_dispatch:

jobs:
  harvest:
    runs-on: ubuntu-latest
    concurrency:
      group: gb2b-harvest
      cancel-in-progress: true
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          python -m pip install requests pandas beautifulsoup4 xlsxwriter

      - name: Check secrets presence (safe)
        run: |
          [ -n "${SERPAPI_KEY:-}" ] && echo "SERPAPI_KEY: set" || echo "SERPAPI_KEY: missing"
          [ -n "${BING_API_KEY:-}" ] && echo "BING_API_KEY: set" || echo "BING_API_KEY: missing"
          [ -n "${NEWSAPI_KEY:-}" ] && echo "NEWSAPI_KEY: set" || echo "NEWSAPI_KEY: missing"

      - name: Verify repo files before run
        run: |
          pwd
          ls -la

      - name: Run harvester
        env:
          SERPAPI_KEY: ${{ secrets.SERPAPI_KEY }}     # optional
          BING_API_KEY: ${{ secrets.BING_API_KEY }}   # optional
          BING_ENDPOINT: "https://api.bing.microsoft.com/v7.0/search"
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}     # optional
        run: |
          python lead_harvester.py

      - name: Verify outputs after run
        run: |
          ls -la
          [ -f gb2b_leads.csv ] && echo "CSV present ✅" || echo "CSV missing ❌"

      - name: Ensure CSV exists (debug)
        run: |
          if [ ! -f gb2b_leads.csv ]; then
            echo 'title,url, snippet, source,published_at, market, industry, topic' > gb2b_leads.csv
            echo "Created placeholder gb2b_leads.csv"
          fi
